{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJHefI4IZkaM"
   },
   "source": [
    "# Compile CSVs exported from the GlaSEE pipeline\n",
    "\n",
    "__NOTE:__ You must do one of the following to access your CSVs\n",
    "\n",
    "- Upload this notebook to your Google Drive and run as a Colab notebook.\n",
    "\n",
    "- Download the CSVs locally.\n",
    "\n",
    "- Download Google Drive Desktop or other software for mounting your Drive locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3464,
     "status": "ok",
     "timestamp": 1761242844459,
     "user": {
      "displayName": "Rainey Aberle",
      "userId": "06245029574837198852"
     },
     "user_tz": 240
    },
    "id": "m_GS3ud2HNw1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import os\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrcy1ce0cKqw"
   },
   "source": [
    "## Define path to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 600,
     "status": "ok",
     "timestamp": 1761244006866,
     "user": {
      "displayName": "Rainey Aberle",
      "userId": "06245029574837198852"
     },
     "user_tz": 240
    },
    "id": "kSQuWAlrbxlb",
    "outputId": "cb47f67b-ef5e-4fe9-9b11-14e2997254ad"
   },
   "outputs": [],
   "source": [
    "# If using Google Colab, mount your Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Define to the Google Drive folder with exported CSV files\n",
    "out_path = '/content/drive/My Drive/glacier_snow_cover_exports/'\n",
    "compiled_out_path = '/content/drive/My Drive/glacier_snow_cover_exports_compiled/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oo5TR2WOcRUd"
   },
   "source": [
    "## Compile CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42287,
     "status": "ok",
     "timestamp": 1761242907956,
     "user": {
      "displayName": "Rainey Aberle",
      "userId": "06245029574837198852"
     },
     "user_tz": 240
    },
    "id": "RaZw5gITHQTV",
    "outputId": "7cf7a0c6-96be-4867-f184-13923ad415cf"
   },
   "outputs": [],
   "source": [
    "# -----Option 1: enter glacier IDs manually\n",
    "# May be desired if some are glaciers still exporting, etc.\n",
    "# glacier_IDs = ['G219787E60289N']\n",
    "\n",
    "# -----Option 2: Grab all the glacier IDs in the folder\n",
    "all_files = glob(os.path.join(out_path, '*.csv'))\n",
    "ids = []\n",
    "for file in all_files:\n",
    "  id = file.split('/')[-1].split('_')[0]\n",
    "  ids.append(id)\n",
    "glacier_IDs = sorted(list(set(ids)))\n",
    "\n",
    "print('Number of unique glacier IDs:', len(glacier_IDs))\n",
    "print(glacier_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 999642,
     "status": "ok",
     "timestamp": 1761245090418,
     "user": {
      "displayName": "Rainey Aberle",
      "userId": "06245029574837198852"
     },
     "user_tz": 240
    },
    "id": "m8OK81EjNadC",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "5584d484-0a2e-4cb1-89b6-8e8ab341a42e"
   },
   "outputs": [],
   "source": [
    "# Iterate over glacier IDs\n",
    "for i, glacier_ID in enumerate(glacier_IDs):\n",
    "  print('\\n', i, glacier_ID)\n",
    "\n",
    "  # Define output file name for compiled time series\n",
    "  out_fn = os.path.join(compiled_out_path, glacier_ID + '_timeseries.csv')\n",
    "\n",
    "  # Check if compiled CSV already exists and if there are new raw files\n",
    "  files = glob(os.path.join(out_path, glacier_ID + '*snow_cover_stats*.csv'))\n",
    "  if os.path.exists(out_fn) and len(files) > 0:\n",
    "      print(f'Compiled CSV already exists. Checking for new snow cover stats files.')\n",
    "\n",
    "      # Load the existing compiled CSV\n",
    "      try:\n",
    "          glacier_df = pd.read_csv(out_fn)\n",
    "          print('Existing compiled time series loaded.')\n",
    "      except:\n",
    "          print(f'Error reading existing compiled CSV: {out_fn}. Recompiling all files.')\n",
    "          glacier_df = pd.DataFrame() # Initialize an empty DataFrame if there's an error\n",
    "\n",
    "      dfs = [glacier_df] # Start with the existing data\n",
    "\n",
    "      # Iterate over new CSVs\n",
    "      print(f'Found {len(files)} CSVs to potentially add')\n",
    "      for file in tqdm(files):\n",
    "          try:\n",
    "              df = pd.read_csv(file)\n",
    "              # Check if this file's data is already in the compiled DataFrame\n",
    "              if not df.equals(glacier_df[glacier_df['system:index'] == df['system:index'].iloc[0]]):\n",
    "                  dfs.append(df)\n",
    "          except: # CSVs fail opening when empty\n",
    "              continue\n",
    "\n",
    "      # Compile and save new CSV to file\n",
    "      if len(dfs) > 1: # Only compile if new data was added\n",
    "          # concatenate dataframes\n",
    "          glacier_df = pd.concat(dfs)\n",
    "\n",
    "          # sort by date\n",
    "          glacier_df = glacier_df.sort_values(by='date')\n",
    "\n",
    "          # get rid of empty columns\n",
    "          glacier_df = glacier_df.drop(columns=['system:index', '.geo'], errors='ignore')\n",
    "\n",
    "          # save to file\n",
    "          glacier_df.to_csv(out_fn, index=False)\n",
    "          print('Compiled time series updated and saved to file:', out_fn)\n",
    "      else:\n",
    "          print('No new data to add.')\n",
    "\n",
    "  elif os.path.exists(out_fn) and len(files) == 0:\n",
    "      print(f'Compiled CSV already exists and no new snow cover stats files found. Skipping.')\n",
    "\n",
    "  elif not os.path.exists(out_fn) and len(files) > 0:\n",
    "      print(f'Compiled CSV does not exist. Compiling {len(files)} CSVs.')\n",
    "      dfs = []\n",
    "      for file in tqdm(files):\n",
    "          try:\n",
    "              df = pd.read_csv(file)\n",
    "              dfs.append(df)\n",
    "          except:\n",
    "              # print('Error reading',file)\n",
    "              continue\n",
    "\n",
    "      if len(dfs) > 0:\n",
    "          # concatenate dataframes\n",
    "          glacier_df = pd.concat(dfs)\n",
    "\n",
    "          # sort by date\n",
    "          glacier_df = glacier_df.sort_values(by='date')\n",
    "\n",
    "          # get rid of empty columns\n",
    "          glacier_df = glacier_df.drop(columns=['system:index', '.geo'], errors='ignore')\n",
    "\n",
    "          # save to file\n",
    "          glacier_df.to_csv(out_fn, index=False)\n",
    "          print('Compiled time series saved to file:', out_fn)\n",
    "      else:\n",
    "          print('No data found to compile.')\n",
    "  else:\n",
    "      print('No compiled CSV and no snow cover stats files found. Skipping.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNcXcLeBWoyx"
   },
   "source": [
    "## Optional: delete the raw files\n",
    "\n",
    "Commented out for now to avoid accidents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1761245382675,
     "user": {
      "displayName": "Rainey Aberle",
      "userId": "06245029574837198852"
     },
     "user_tz": 240
    },
    "id": "ZGYLFsyUWtd8"
   },
   "outputs": [],
   "source": [
    "# for glacier_ID in tqdm(glacier_IDs):\n",
    "#   raw_files = glob(os.path.join(out_path, glacier_ID + '*snow_cover_stats*.csv'))\n",
    "#   for file in raw_files:\n",
    "#     os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzhPguQobWnM"
   },
   "source": [
    "## Plot some time series data for each glacier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xhLfIOIaR_et"
   },
   "outputs": [],
   "source": [
    "# Iterate over glacier IDs\n",
    "for glacier_ID in glacier_IDs:\n",
    "  # load compiled time series\n",
    "  df = pd.read_csv(os.path.join(out_path, glacier_ID + '_timeseries.csv'))\n",
    "  df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "  # plot\n",
    "  fig, ax = plt.subplots(figsize=(8,3))\n",
    "  sns.scatterplot(df, x='date', y='transient_AAR', hue='source', sizes=10)\n",
    "  ax.set_title(glacier_ID)\n",
    "  ax.set_ylim(-0.1, 1.1)\n",
    "  plt.grid()\n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "glasee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
